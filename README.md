# âš–ï¸ LexAnalyzer - Sistema de AnÃ¡lisis de Contratos Legales

Sistema completo para anÃ¡lisis inteligente de contratos legales usando grandes modelos de lenguaje (LLMs), GeneraciÃ³n Aumentada por RecuperaciÃ³n (RAG) y Agentes especializados.

## ğŸ¯ Â¿QuÃ© hace este sistema?

Analiza contratos legales automÃ¡ticamente y extrae de forma estructurada:
- âœ… ClÃ¡usulas principales
- âš ï¸ Riesgos legales y penalizaciones
- ğŸ“Š Obligaciones de las partes
- ğŸ” ComparaciÃ³n con contratos estÃ¡ndar
- ğŸ’¡ Recomendaciones de negociaciÃ³n

## ğŸ§  Arquitectura

```text
Usuario â†’ Frontend (Web) â†’ Backend (Go) â†’ RAG Service (Python/FastAPI) â†’ Groq / Ollama (LLM)
                                                   â†“
                                         ChromaDB (Vector Store)
                                                   â†“
                                        4 Agentes Especializados
```

El sistema ahora incluye una **Base de Conocimiento (Knowledge Base)** que soporta la ingesta nativa de mÃºltiples formatos de documentos legales para enriquecer el contexto del anÃ¡lisis: `.pdf`, `.docx`, `.txt`, `.csv`, `.md` y `.json/.jsonl`.

## âš¡ Quick Start

AsegÃºrate de tener Docker y Docker Compose instalados.

1. **Configurar API (Importante)**
   Crea un archivo `.env` en la raÃ­z del proyecto y aÃ±ade tu API Key de Groq (el proveedor recomendado por su extrema velocidad y gratuidad):
   ```env
   GROQ_API_KEY=tu_api_key_aqui
   LLM_PROVIDER=groq
   ```

2. **Lanzar todo el ecosistema**
   Todos los microservicios estÃ¡n orquestados; basta con un solo comando:
   ```bash
   docker-compose up --build
   ```
   *(Nota: La primera vez tardarÃ¡ varios minutos en descargar los modelos de embeddings de Python).*

3. **Acceder a la Interfaz**
   Abre en tu navegador: http://localhost:3000

## ğŸ”‘ Conceptos Importantes

### âœ… Selector de Modelos DinÃ¡mico
La interfaz de *Contract Analysis* incluye un menÃº desplegable que lista dinÃ¡micamente los modelos disponibles conectados al sistema, divididos en:
- **Modelos Base:** Modelos fundacionales listos para uso rÃ¡pido (ej. Llama 3).
- **Modelos Fine-tuned:** Modelos reentrenados y especializados en el mÃ³dulo de *Training* que han finalizado su aprendizaje con Ã©xito.

### â˜ï¸ Groq vs Ollama
**Groq (Recomendado - Por defecto):**
- API en la nube gratuita. Inferencia ultra-rÃ¡pida (500+ tokens/segundo).
- No requiere hardware local sofisticado.

**Ollama (Opcional - Local):**
- 100% privado y offline.
- Requiere tener el modelo descargado localmente (`ollama pull llama3.2`) y cambiar en `.env`: `LLM_PROVIDER=ollama`.

## ğŸ› ï¸ Servicios Activos

Al levantar el sistema, se despliegan automÃ¡ticamente los siguientes microservicios internos:

| Servicio | Puerto | DescripciÃ³n |
|----------|--------|-------------|
| Frontend | 3000 | Interfaz web HTML/JS servida por Nginx |
| Backend API | 8080 | API REST ultra-rÃ¡pida desarrollada en Go |
| RAG Service | 8001 | Motor de IA en Python (FastAPI, Langchain, ChromaDB) |
| PostgreSQL | 5432 | Base de datos relacional para metadatos |
| MinIO | 9000 | Object Storage (clon S3) para almacenar los PDFs y documentos |

## ğŸ§ª Estructura BÃ¡sica del Proyecto

```
contracts/
â”œâ”€â”€ backend/                    # API Go (GestiÃ³n de base de datos y archivos)
â”‚   â””â”€â”€ services/               # Motor de IA en Python (RAG, Agentes, embeddings)
â”œâ”€â”€ frontend/                   # Interfaz de Usuario (HTML, Vanilla JS, CSS)
â”œâ”€â”€ chroma_db/                  # Base de datos vectorial persistente
â”œâ”€â”€ data/                       # Datasets de ejemplo
â””â”€â”€ docker-compose.yml          # Orquestador
```

## ğŸš¨ Troubleshooting

- **Error "Failed to load" o "Cannot connection to backend":** Verifica que los servicios de Docker se hayan levantado completamente sin errores de memoria (sobre todo el RAG service). AsegÃºrate de acceder a travÃ©s del puerto `3000`.
- **AnÃ¡lisis muy lento:** Si estÃ¡s usando Ollama y no tienes GPU dedicada, el anÃ¡lisis de grandes contratos puede llevar varios minutos. PÃ¡sate a Groq configurando `.env`.
- **Despliegue en la nube:** El proyecto cuenta con un `docker-compose.prod.yml` optimizado para servidores como Oracle Cloud (compatible con ARM Ampere A1 de 24GB).

## ğŸ“„ Licencia

MIT License
